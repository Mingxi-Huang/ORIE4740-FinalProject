{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project : IPO prediction (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ipo</th>\n",
       "      <th>name</th>\n",
       "      <th>funded_object_id</th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wetpaint</td>\n",
       "      <td>c:1</td>\n",
       "      <td>9</td>\n",
       "      <td>39750000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FriendFeed</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobclix</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>c:10015</td>\n",
       "      <td>19</td>\n",
       "      <td>68069200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>MTPV</td>\n",
       "      <td>c:100155</td>\n",
       "      <td>5</td>\n",
       "      <td>10125293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>9302</td>\n",
       "      <td>0</td>\n",
       "      <td>DECA</td>\n",
       "      <td>c:990</td>\n",
       "      <td>7</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>9303</td>\n",
       "      <td>0</td>\n",
       "      <td>wunderloop</td>\n",
       "      <td>c:992</td>\n",
       "      <td>4</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9304</th>\n",
       "      <td>9304</td>\n",
       "      <td>0</td>\n",
       "      <td>FastCustomer</td>\n",
       "      <td>c:99669</td>\n",
       "      <td>6</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305</th>\n",
       "      <td>9305</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbra</td>\n",
       "      <td>c:997</td>\n",
       "      <td>9</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>9306</td>\n",
       "      <td>0</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>c:9972</td>\n",
       "      <td>14</td>\n",
       "      <td>82500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9307 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ipo          name funded_object_id  num_investors  \\\n",
       "0              0    0      Wetpaint              c:1              9   \n",
       "1              1    0    FriendFeed           c:1001              3   \n",
       "2              2    0       Mobclix          c:10014              1   \n",
       "3              3    0        Fitbit          c:10015             19   \n",
       "4              4    0          MTPV         c:100155              5   \n",
       "...          ...  ...           ...              ...            ...   \n",
       "9302        9302    0          DECA            c:990              7   \n",
       "9303        9303    0    wunderloop            c:992              4   \n",
       "9304        9304    0  FastCustomer          c:99669              6   \n",
       "9305        9305    0        Zimbra            c:997              9   \n",
       "9306        9306    0          Lyft           c:9972             14   \n",
       "\n",
       "      raised_amount_usd  type_Bachelor  type_Master  type_Other  \\\n",
       "0            39750000.0            7.0          5.0         1.0   \n",
       "1             5000000.0            4.0          6.0         0.0   \n",
       "2                   0.0            2.0          1.0         2.0   \n",
       "3            68069200.0            2.0          7.0         2.0   \n",
       "4            10125293.0            1.0          3.0         0.0   \n",
       "...                 ...            ...          ...         ...   \n",
       "9302         15000000.0            2.0          3.0         1.0   \n",
       "9303         10000000.0            1.0          4.0         2.0   \n",
       "9304           750000.0            1.0          0.0         0.0   \n",
       "9305         14500000.0            2.0          7.0         2.0   \n",
       "9306         82500000.0            5.0          2.0         2.0   \n",
       "\n",
       "      type_OtherDiploma  ...  state_TN  state_TX  state_UT  state_VA  \\\n",
       "0                   0.0  ...       0.0       0.0       0.0       0.0   \n",
       "1                   0.0  ...       0.0       0.0       0.0       0.0   \n",
       "2                   0.0  ...       0.0       0.0       0.0       0.0   \n",
       "3                   0.0  ...       0.0       0.0       0.0       0.0   \n",
       "4                   0.0  ...       0.0       1.0       0.0       0.0   \n",
       "...                 ...  ...       ...       ...       ...       ...   \n",
       "9302                0.0  ...       0.0       0.0       0.0       0.0   \n",
       "9303                0.0  ...       0.0       0.0       0.0       0.0   \n",
       "9304                0.0  ...       0.0       0.0       0.0       0.0   \n",
       "9305                0.0  ...       0.0       0.0       0.0       0.0   \n",
       "9306                0.0  ...       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_VT  state_WA  state_WI  state_WV  state_WY  state_not specified  \n",
       "0          0.0       1.0       0.0       0.0       0.0                  0.0  \n",
       "1          0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "2          0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "3          0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "4          0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "...        ...       ...       ...       ...       ...                  ...  \n",
       "9302       0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "9303       0.0       0.0       0.0       0.0       0.0                  1.0  \n",
       "9304       0.0       1.0       0.0       0.0       0.0                  0.0  \n",
       "9305       0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "9306       0.0       0.0       0.0       0.0       0.0                  0.0  \n",
       "\n",
       "[9307 rows x 163 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_final.csv\")\n",
    "df\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipo</th>\n",
       "      <th>name</th>\n",
       "      <th>funded_object_id</th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wetpaint</td>\n",
       "      <td>c:1</td>\n",
       "      <td>9</td>\n",
       "      <td>39750000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>FriendFeed</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mobclix</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>c:10015</td>\n",
       "      <td>19</td>\n",
       "      <td>68069200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MTPV</td>\n",
       "      <td>c:100155</td>\n",
       "      <td>5</td>\n",
       "      <td>10125293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>0</td>\n",
       "      <td>DECA</td>\n",
       "      <td>c:990</td>\n",
       "      <td>7</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>0</td>\n",
       "      <td>wunderloop</td>\n",
       "      <td>c:992</td>\n",
       "      <td>4</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9304</th>\n",
       "      <td>0</td>\n",
       "      <td>FastCustomer</td>\n",
       "      <td>c:99669</td>\n",
       "      <td>6</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305</th>\n",
       "      <td>0</td>\n",
       "      <td>Zimbra</td>\n",
       "      <td>c:997</td>\n",
       "      <td>9</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>0</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>c:9972</td>\n",
       "      <td>14</td>\n",
       "      <td>82500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9307 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ipo          name funded_object_id  num_investors  raised_amount_usd  \\\n",
       "0       0      Wetpaint              c:1              9         39750000.0   \n",
       "1       0    FriendFeed           c:1001              3          5000000.0   \n",
       "2       0       Mobclix          c:10014              1                0.0   \n",
       "3       0        Fitbit          c:10015             19         68069200.0   \n",
       "4       0          MTPV         c:100155              5         10125293.0   \n",
       "...   ...           ...              ...            ...                ...   \n",
       "9302    0          DECA            c:990              7         15000000.0   \n",
       "9303    0    wunderloop            c:992              4         10000000.0   \n",
       "9304    0  FastCustomer          c:99669              6           750000.0   \n",
       "9305    0        Zimbra            c:997              9         14500000.0   \n",
       "9306    0          Lyft           c:9972             14         82500000.0   \n",
       "\n",
       "      type_Bachelor  type_Master  type_Other  type_OtherDiploma  type_PhD  \\\n",
       "0               7.0          5.0         1.0                0.0       1.0   \n",
       "1               4.0          6.0         0.0                0.0       1.0   \n",
       "2               2.0          1.0         2.0                0.0       1.0   \n",
       "3               2.0          7.0         2.0                0.0       0.0   \n",
       "4               1.0          3.0         0.0                0.0       1.0   \n",
       "...             ...          ...         ...                ...       ...   \n",
       "9302            2.0          3.0         1.0                0.0       0.0   \n",
       "9303            1.0          4.0         2.0                0.0       0.0   \n",
       "9304            1.0          0.0         0.0                0.0       0.0   \n",
       "9305            2.0          7.0         2.0                0.0       1.0   \n",
       "9306            5.0          2.0         2.0                0.0       1.0   \n",
       "\n",
       "      ...  state_TN  state_TX  state_UT  state_VA  state_VT  state_WA  \\\n",
       "0     ...       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "1     ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2     ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3     ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4     ...       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "9302  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9303  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9304  ...       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "9305  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9306  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_WI  state_WV  state_WY  state_not specified  \n",
       "0          0.0       0.0       0.0                  0.0  \n",
       "1          0.0       0.0       0.0                  0.0  \n",
       "2          0.0       0.0       0.0                  0.0  \n",
       "3          0.0       0.0       0.0                  0.0  \n",
       "4          0.0       0.0       0.0                  0.0  \n",
       "...        ...       ...       ...                  ...  \n",
       "9302       0.0       0.0       0.0                  0.0  \n",
       "9303       0.0       0.0       0.0                  1.0  \n",
       "9304       0.0       0.0       0.0                  0.0  \n",
       "9305       0.0       0.0       0.0                  0.0  \n",
       "9306       0.0       0.0       0.0                  0.0  \n",
       "\n",
       "[9307 rows x 162 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_success = df[df['ipo'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipo</th>\n",
       "      <th>name</th>\n",
       "      <th>funded_object_id</th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Attunity</td>\n",
       "      <td>c:100844</td>\n",
       "      <td>4</td>\n",
       "      <td>10500000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>Global Crossing</td>\n",
       "      <td>c:10241</td>\n",
       "      <td>1</td>\n",
       "      <td>41000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>Tremor Video</td>\n",
       "      <td>c:104377</td>\n",
       "      <td>20</td>\n",
       "      <td>116400000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "      <td>Inuvo</td>\n",
       "      <td>c:10614</td>\n",
       "      <td>5</td>\n",
       "      <td>4200000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>YuMe</td>\n",
       "      <td>c:1063</td>\n",
       "      <td>28</td>\n",
       "      <td>72900000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9053</th>\n",
       "      <td>1</td>\n",
       "      <td>QlikTech</td>\n",
       "      <td>c:8530</td>\n",
       "      <td>2</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9084</th>\n",
       "      <td>1</td>\n",
       "      <td>Inogen</td>\n",
       "      <td>c:85862</td>\n",
       "      <td>1</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9224</th>\n",
       "      <td>1</td>\n",
       "      <td>RingCentral</td>\n",
       "      <td>c:949</td>\n",
       "      <td>16</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9235</th>\n",
       "      <td>1</td>\n",
       "      <td>Zillow</td>\n",
       "      <td>c:959</td>\n",
       "      <td>4</td>\n",
       "      <td>96627980.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>1</td>\n",
       "      <td>Palo Alto Networks</td>\n",
       "      <td>c:9743</td>\n",
       "      <td>12</td>\n",
       "      <td>328600000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ipo                name funded_object_id  num_investors  \\\n",
       "16      1            Attunity         c:100844              4   \n",
       "44      1     Global Crossing          c:10241              1   \n",
       "77      1        Tremor Video         c:104377             20   \n",
       "117     1               Inuvo          c:10614              5   \n",
       "120     1                YuMe           c:1063             28   \n",
       "...   ...                 ...              ...            ...   \n",
       "9053    1            QlikTech           c:8530              2   \n",
       "9084    1              Inogen          c:85862              1   \n",
       "9224    1         RingCentral            c:949             16   \n",
       "9235    1              Zillow            c:959              4   \n",
       "9273    1  Palo Alto Networks           c:9743             12   \n",
       "\n",
       "      raised_amount_usd  type_Bachelor  type_Master  type_Other  \\\n",
       "16           10500000.0            1.0          0.0         0.0   \n",
       "44           41000000.0            4.0          5.0         1.0   \n",
       "77          116400000.0            4.0          5.0         1.0   \n",
       "117           4200000.0            1.0          3.0         2.0   \n",
       "120          72900000.0            6.0         15.0         1.0   \n",
       "...                 ...            ...          ...         ...   \n",
       "9053         12500000.0            2.0          1.0         2.0   \n",
       "9084         20000000.0            0.0          2.0         0.0   \n",
       "9224         44000000.0            9.0         15.0         1.0   \n",
       "9235         96627980.0           12.0          5.0         0.0   \n",
       "9273        328600000.0           15.0         13.0         2.0   \n",
       "\n",
       "      type_OtherDiploma  type_PhD  ...  state_TN  state_TX  state_UT  \\\n",
       "16                  0.0       0.0  ...       0.0       0.0       0.0   \n",
       "44                  0.0       1.0  ...       0.0       0.0       0.0   \n",
       "77                  0.0       1.0  ...       0.0       0.0       0.0   \n",
       "117                 0.0       1.0  ...       0.0       0.0       0.0   \n",
       "120                 0.0       0.0  ...       0.0       0.0       0.0   \n",
       "...                 ...       ...  ...       ...       ...       ...   \n",
       "9053                0.0       0.0  ...       0.0       0.0       0.0   \n",
       "9084                0.0       3.0  ...       0.0       0.0       0.0   \n",
       "9224                0.0       2.0  ...       0.0       0.0       0.0   \n",
       "9235                0.0       4.0  ...       0.0       0.0       0.0   \n",
       "9273                0.0       1.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "      state_VA  state_VT  state_WA  state_WI  state_WV  state_WY  \\\n",
       "16         0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "44         0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "77         0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "117        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "120        0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...   \n",
       "9053       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9084       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9224       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9235       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "9273       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_not specified  \n",
       "16                    0.0  \n",
       "44                    0.0  \n",
       "77                    0.0  \n",
       "117                   0.0  \n",
       "120                   0.0  \n",
       "...                   ...  \n",
       "9053                  0.0  \n",
       "9084                  0.0  \n",
       "9224                  0.0  \n",
       "9235                  0.0  \n",
       "9273                  0.0  \n",
       "\n",
       "[230 rows x 162 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipo_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_dup = df.append(ipo_success, ignore_index=True)\n",
    "for i in range(19):\n",
    "    df_w_dup = df_w_dup.append(ipo_success, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipo</th>\n",
       "      <th>name</th>\n",
       "      <th>funded_object_id</th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wetpaint</td>\n",
       "      <td>c:1</td>\n",
       "      <td>9</td>\n",
       "      <td>39750000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>FriendFeed</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mobclix</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>c:10015</td>\n",
       "      <td>19</td>\n",
       "      <td>68069200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MTPV</td>\n",
       "      <td>c:100155</td>\n",
       "      <td>5</td>\n",
       "      <td>10125293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>1</td>\n",
       "      <td>QlikTech</td>\n",
       "      <td>c:8530</td>\n",
       "      <td>2</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13903</th>\n",
       "      <td>1</td>\n",
       "      <td>Inogen</td>\n",
       "      <td>c:85862</td>\n",
       "      <td>1</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>1</td>\n",
       "      <td>RingCentral</td>\n",
       "      <td>c:949</td>\n",
       "      <td>16</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>1</td>\n",
       "      <td>Zillow</td>\n",
       "      <td>c:959</td>\n",
       "      <td>4</td>\n",
       "      <td>96627980.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>1</td>\n",
       "      <td>Palo Alto Networks</td>\n",
       "      <td>c:9743</td>\n",
       "      <td>12</td>\n",
       "      <td>328600000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13907 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ipo                name funded_object_id  num_investors  \\\n",
       "0        0            Wetpaint              c:1              9   \n",
       "1        0          FriendFeed           c:1001              3   \n",
       "2        0             Mobclix          c:10014              1   \n",
       "3        0              Fitbit          c:10015             19   \n",
       "4        0                MTPV         c:100155              5   \n",
       "...    ...                 ...              ...            ...   \n",
       "13902    1            QlikTech           c:8530              2   \n",
       "13903    1              Inogen          c:85862              1   \n",
       "13904    1         RingCentral            c:949             16   \n",
       "13905    1              Zillow            c:959              4   \n",
       "13906    1  Palo Alto Networks           c:9743             12   \n",
       "\n",
       "       raised_amount_usd  type_Bachelor  type_Master  type_Other  \\\n",
       "0             39750000.0            7.0          5.0         1.0   \n",
       "1              5000000.0            4.0          6.0         0.0   \n",
       "2                    0.0            2.0          1.0         2.0   \n",
       "3             68069200.0            2.0          7.0         2.0   \n",
       "4             10125293.0            1.0          3.0         0.0   \n",
       "...                  ...            ...          ...         ...   \n",
       "13902         12500000.0            2.0          1.0         2.0   \n",
       "13903         20000000.0            0.0          2.0         0.0   \n",
       "13904         44000000.0            9.0         15.0         1.0   \n",
       "13905         96627980.0           12.0          5.0         0.0   \n",
       "13906        328600000.0           15.0         13.0         2.0   \n",
       "\n",
       "       type_OtherDiploma  type_PhD  ...  state_TN  state_TX  state_UT  \\\n",
       "0                    0.0       1.0  ...       0.0       0.0       0.0   \n",
       "1                    0.0       1.0  ...       0.0       0.0       0.0   \n",
       "2                    0.0       1.0  ...       0.0       0.0       0.0   \n",
       "3                    0.0       0.0  ...       0.0       0.0       0.0   \n",
       "4                    0.0       1.0  ...       0.0       1.0       0.0   \n",
       "...                  ...       ...  ...       ...       ...       ...   \n",
       "13902                0.0       0.0  ...       0.0       0.0       0.0   \n",
       "13903                0.0       3.0  ...       0.0       0.0       0.0   \n",
       "13904                0.0       2.0  ...       0.0       0.0       0.0   \n",
       "13905                0.0       4.0  ...       0.0       0.0       0.0   \n",
       "13906                0.0       1.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "       state_VA  state_VT  state_WA  state_WI  state_WV  state_WY  \\\n",
       "0           0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "1           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "13902       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "13903       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "13904       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "13905       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "13906       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       state_not specified  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "...                    ...  \n",
       "13902                  0.0  \n",
       "13903                  0.0  \n",
       "13904                  0.0  \n",
       "13905                  0.0  \n",
       "13906                  0.0  \n",
       "\n",
       "[13907 rows x 162 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_w_dup['ipo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_w_dup.columns\n",
    "features = features.drop(['name', 'ipo','funded_object_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>subject_Accounting</th>\n",
       "      <th>subject_Accounting and Finance</th>\n",
       "      <th>subject_Advertising</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.441496</td>\n",
       "      <td>-0.112556</td>\n",
       "      <td>0.138151</td>\n",
       "      <td>-0.030574</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>3.791080</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.495962</td>\n",
       "      <td>-0.224900</td>\n",
       "      <td>-0.021963</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.808448</td>\n",
       "      <td>-0.241064</td>\n",
       "      <td>-0.128706</td>\n",
       "      <td>-0.216062</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.003926</td>\n",
       "      <td>-0.021002</td>\n",
       "      <td>-0.128706</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.305876</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.183476</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-0.182077</td>\n",
       "      <td>-0.123318</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>3.894018</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>-0.652205</td>\n",
       "      <td>-0.200653</td>\n",
       "      <td>-0.128706</td>\n",
       "      <td>-0.216062</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.305876</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13903</th>\n",
       "      <td>-0.808448</td>\n",
       "      <td>-0.176406</td>\n",
       "      <td>-0.235449</td>\n",
       "      <td>-0.169690</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>0.299162</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>1.535197</td>\n",
       "      <td>-0.098816</td>\n",
       "      <td>0.244894</td>\n",
       "      <td>0.433148</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>0.097482</td>\n",
       "      <td>1.483018</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>-0.339719</td>\n",
       "      <td>0.071326</td>\n",
       "      <td>0.405008</td>\n",
       "      <td>-0.030574</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>0.500841</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>3.791080</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>0.910225</td>\n",
       "      <td>0.821271</td>\n",
       "      <td>0.565122</td>\n",
       "      <td>0.340404</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>3.315152</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13907 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_investors  raised_amount_usd  type_Bachelor  type_Master  \\\n",
       "0           0.441496          -0.112556       0.138151    -0.030574   \n",
       "1          -0.495962          -0.224900      -0.021963     0.015799   \n",
       "2          -0.808448          -0.241064      -0.128706    -0.216062   \n",
       "3           2.003926          -0.021002      -0.128706     0.062171   \n",
       "4          -0.183476          -0.208330      -0.182077    -0.123318   \n",
       "...              ...                ...            ...          ...   \n",
       "13902      -0.652205          -0.200653      -0.128706    -0.216062   \n",
       "13903      -0.808448          -0.176406      -0.235449    -0.169690   \n",
       "13904       1.535197          -0.098816       0.244894     0.433148   \n",
       "13905      -0.339719           0.071326       0.405008    -0.030574   \n",
       "13906       0.910225           0.821271       0.565122     0.340404   \n",
       "\n",
       "       type_Other  type_OtherDiploma  type_PhD  subject_Accounting  \\\n",
       "0       -0.009845          -0.095376 -0.104197           -0.349116   \n",
       "1       -0.222782          -0.095376 -0.104197           -0.349116   \n",
       "2        0.203091          -0.095376 -0.104197           -0.349116   \n",
       "3        0.203091          -0.095376 -0.305876           -0.349116   \n",
       "4       -0.222782          -0.095376 -0.104197           -0.349116   \n",
       "...           ...                ...       ...                 ...   \n",
       "13902    0.203091          -0.095376 -0.305876           -0.349116   \n",
       "13903   -0.222782          -0.095376  0.299162           -0.349116   \n",
       "13904   -0.009845          -0.095376  0.097482            1.483018   \n",
       "13905   -0.222782          -0.095376  0.500841           -0.349116   \n",
       "13906    0.203091          -0.095376 -0.104197            3.315152   \n",
       "\n",
       "       subject_Accounting and Finance  subject_Advertising  ...  state_TN  \\\n",
       "0                           -0.144765            -0.120696  ... -0.077954   \n",
       "1                           -0.144765            -0.120696  ... -0.077954   \n",
       "2                           -0.144765            -0.120696  ... -0.077954   \n",
       "3                           -0.144765            -0.120696  ... -0.077954   \n",
       "4                           -0.144765            -0.120696  ... -0.077954   \n",
       "...                               ...                  ...  ...       ...   \n",
       "13902                       -0.144765            -0.120696  ... -0.077954   \n",
       "13903                       -0.144765            -0.120696  ... -0.077954   \n",
       "13904                       -0.144765            -0.120696  ... -0.077954   \n",
       "13905                       -0.144765            -0.120696  ... -0.077954   \n",
       "13906                       -0.144765            -0.120696  ... -0.077954   \n",
       "\n",
       "       state_TX  state_UT  state_VA  state_VT  state_WA  state_WI  state_WV  \\\n",
       "0     -0.211365 -0.111252  -0.15199 -0.029387  3.791080 -0.060712 -0.011993   \n",
       "1     -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "2     -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "3     -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "4      3.894018 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13902 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "13903 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "13904 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "13905 -0.211365 -0.111252  -0.15199 -0.029387  3.791080 -0.060712 -0.011993   \n",
       "13906 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "\n",
       "       state_WY  state_not specified  \n",
       "0     -0.011993            -0.120625  \n",
       "1     -0.011993            -0.120625  \n",
       "2     -0.011993            -0.120625  \n",
       "3     -0.011993            -0.120625  \n",
       "4     -0.011993            -0.120625  \n",
       "...         ...                  ...  \n",
       "13902 -0.011993            -0.120625  \n",
       "13903 -0.011993            -0.120625  \n",
       "13904 -0.011993            -0.120625  \n",
       "13905 -0.011993            -0.120625  \n",
       "13906 -0.011993            -0.120625  \n",
       "\n",
       "[13907 rows x 159 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling on features\n",
    "df_w_dup[features] = StandardScaler().fit_transform(df_w_dup[features])\n",
    "df_w_dup[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing weighted accuracy from CS4780\n",
    "def weighted_accuracy(pred, true):\n",
    "    assert(len(pred) == len(true))\n",
    "    num_labels = len(true)\n",
    "    num_pos = sum(true)\n",
    "    num_neg = num_labels - num_pos\n",
    "    frac_pos = num_pos/num_labels\n",
    "    weight_pos = 1/frac_pos\n",
    "    weight_neg = 1/(1-frac_pos)\n",
    "    num_pos_correct = 0\n",
    "    num_neg_correct = 0\n",
    "    for pred_i, true_i in zip(pred, true):\n",
    "        num_pos_correct += (pred_i == true_i and true_i == 1)\n",
    "        num_neg_correct += (pred_i == true_i and true_i == 0)\n",
    "    weighted_accuracy = ((weight_pos * num_pos_correct) \n",
    "                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))\n",
    "    return weighted_accuracy\n",
    "\n",
    "#custom scorer based on weighted accuracy function given\n",
    "def weighted_accuracy_switched(y, y_pred):\n",
    "    return weighted_accuracy(y_pred, y)\n",
    "\n",
    "weighted_accuracy_score = make_scorer(weighted_accuracy_switched, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_w_dup['ipo']\n",
    "X = df_w_dup[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>subject_Accounting</th>\n",
       "      <th>subject_Accounting and Finance</th>\n",
       "      <th>subject_Advertising</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.441496</td>\n",
       "      <td>-0.112556</td>\n",
       "      <td>0.138151</td>\n",
       "      <td>-0.030574</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>3.791080</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.495962</td>\n",
       "      <td>-0.224900</td>\n",
       "      <td>-0.021963</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.808448</td>\n",
       "      <td>-0.241064</td>\n",
       "      <td>-0.128706</td>\n",
       "      <td>-0.216062</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.003926</td>\n",
       "      <td>-0.021002</td>\n",
       "      <td>-0.128706</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.305876</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.183476</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-0.182077</td>\n",
       "      <td>-0.123318</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>3.894018</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>-0.652205</td>\n",
       "      <td>-0.200653</td>\n",
       "      <td>-0.128706</td>\n",
       "      <td>-0.216062</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.305876</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13903</th>\n",
       "      <td>-0.808448</td>\n",
       "      <td>-0.176406</td>\n",
       "      <td>-0.235449</td>\n",
       "      <td>-0.169690</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>0.299162</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>1.535197</td>\n",
       "      <td>-0.098816</td>\n",
       "      <td>0.244894</td>\n",
       "      <td>0.433148</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>0.097482</td>\n",
       "      <td>1.483018</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>-0.339719</td>\n",
       "      <td>0.071326</td>\n",
       "      <td>0.405008</td>\n",
       "      <td>-0.030574</td>\n",
       "      <td>-0.222782</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>0.500841</td>\n",
       "      <td>-0.349116</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>3.791080</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>0.910225</td>\n",
       "      <td>0.821271</td>\n",
       "      <td>0.565122</td>\n",
       "      <td>0.340404</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>-0.095376</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>3.315152</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077954</td>\n",
       "      <td>-0.211365</td>\n",
       "      <td>-0.111252</td>\n",
       "      <td>-0.15199</td>\n",
       "      <td>-0.029387</td>\n",
       "      <td>-0.210328</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.120625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13907 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_investors  raised_amount_usd  type_Bachelor  type_Master  \\\n",
       "0           0.441496          -0.112556       0.138151    -0.030574   \n",
       "1          -0.495962          -0.224900      -0.021963     0.015799   \n",
       "2          -0.808448          -0.241064      -0.128706    -0.216062   \n",
       "3           2.003926          -0.021002      -0.128706     0.062171   \n",
       "4          -0.183476          -0.208330      -0.182077    -0.123318   \n",
       "...              ...                ...            ...          ...   \n",
       "13902      -0.652205          -0.200653      -0.128706    -0.216062   \n",
       "13903      -0.808448          -0.176406      -0.235449    -0.169690   \n",
       "13904       1.535197          -0.098816       0.244894     0.433148   \n",
       "13905      -0.339719           0.071326       0.405008    -0.030574   \n",
       "13906       0.910225           0.821271       0.565122     0.340404   \n",
       "\n",
       "       type_Other  type_OtherDiploma  type_PhD  subject_Accounting  \\\n",
       "0       -0.009845          -0.095376 -0.104197           -0.349116   \n",
       "1       -0.222782          -0.095376 -0.104197           -0.349116   \n",
       "2        0.203091          -0.095376 -0.104197           -0.349116   \n",
       "3        0.203091          -0.095376 -0.305876           -0.349116   \n",
       "4       -0.222782          -0.095376 -0.104197           -0.349116   \n",
       "...           ...                ...       ...                 ...   \n",
       "13902    0.203091          -0.095376 -0.305876           -0.349116   \n",
       "13903   -0.222782          -0.095376  0.299162           -0.349116   \n",
       "13904   -0.009845          -0.095376  0.097482            1.483018   \n",
       "13905   -0.222782          -0.095376  0.500841           -0.349116   \n",
       "13906    0.203091          -0.095376 -0.104197            3.315152   \n",
       "\n",
       "       subject_Accounting and Finance  subject_Advertising  ...  state_TN  \\\n",
       "0                           -0.144765            -0.120696  ... -0.077954   \n",
       "1                           -0.144765            -0.120696  ... -0.077954   \n",
       "2                           -0.144765            -0.120696  ... -0.077954   \n",
       "3                           -0.144765            -0.120696  ... -0.077954   \n",
       "4                           -0.144765            -0.120696  ... -0.077954   \n",
       "...                               ...                  ...  ...       ...   \n",
       "13902                       -0.144765            -0.120696  ... -0.077954   \n",
       "13903                       -0.144765            -0.120696  ... -0.077954   \n",
       "13904                       -0.144765            -0.120696  ... -0.077954   \n",
       "13905                       -0.144765            -0.120696  ... -0.077954   \n",
       "13906                       -0.144765            -0.120696  ... -0.077954   \n",
       "\n",
       "       state_TX  state_UT  state_VA  state_VT  state_WA  state_WI  state_WV  \\\n",
       "0     -0.211365 -0.111252  -0.15199 -0.029387  3.791080 -0.060712 -0.011993   \n",
       "1     -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "2     -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "3     -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "4      3.894018 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13902 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "13903 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "13904 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "13905 -0.211365 -0.111252  -0.15199 -0.029387  3.791080 -0.060712 -0.011993   \n",
       "13906 -0.211365 -0.111252  -0.15199 -0.029387 -0.210328 -0.060712 -0.011993   \n",
       "\n",
       "       state_WY  state_not specified  \n",
       "0     -0.011993            -0.120625  \n",
       "1     -0.011993            -0.120625  \n",
       "2     -0.011993            -0.120625  \n",
       "3     -0.011993            -0.120625  \n",
       "4     -0.011993            -0.120625  \n",
       "...         ...                  ...  \n",
       "13902 -0.011993            -0.120625  \n",
       "13903 -0.011993            -0.120625  \n",
       "13904 -0.011993            -0.120625  \n",
       "13905 -0.011993            -0.120625  \n",
       "13906 -0.011993            -0.120625  \n",
       "\n",
       "[13907 rows x 159 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[features] = StandardScaler().fit_transform(df[features])\n",
    "# df[features]\n",
    "# Y = df['ipo']\n",
    "# X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning KNN hyper-parameters for weighted accuracy\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 1, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.991 (+/-0.004) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.991 (+/-0.004) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.981 (+/-0.006) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.982 (+/-0.006) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.972 (+/-0.005) for {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.975 (+/-0.004) for {'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.964 (+/-0.009) for {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.969 (+/-0.008) for {'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.955 (+/-0.008) for {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.961 (+/-0.008) for {'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.945 (+/-0.009) for {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.955 (+/-0.005) for {'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.915 (+/-0.012) for {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.942 (+/-0.008) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.823 (+/-0.029) for {'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.942 (+/-0.007) for {'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.723 (+/-0.023) for {'n_neighbors': 35, 'weights': 'uniform'}\n",
      "0.970 (+/-0.007) for {'n_neighbors': 35, 'weights': 'distance'}\n",
      "0.664 (+/-0.023) for {'n_neighbors': 51, 'weights': 'uniform'}\n",
      "0.975 (+/-0.007) for {'n_neighbors': 51, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2726\n",
      "           1       0.97      1.00      0.99      1447\n",
      "\n",
      "    accuracy                           0.99      4173\n",
      "   macro avg       0.99      0.99      0.99      4173\n",
      "weighted avg       0.99      0.99      0.99      4173\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first try on knn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = [{'n_neighbors':[1, 3, 5, 7, 9, 11, 15, 21, 35, 51], 'weights': ['uniform', 'distance']}]\n",
    "\n",
    "# knn_cv = KNeighborsClassifier(n_neighbors = 3)\n",
    "# knn_cv_scores = cross_val_score(knn_cv, X, Y, cv=5, scoring=weighted_accuracy_score)\n",
    "# # knn_cv_scores\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (knn_cv_scores.mean(), knn_cv_scores.std() * 2))\n",
    "\n",
    "print(\"# Tuning KNN hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "knn_clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, scoring=weighted_accuracy_score)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(knn_clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = knn_clf.cv_results_['mean_test_score']\n",
    "stds = knn_clf.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, knn_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, knn_clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Grid search scores\n",
    "_, ax = plt.subplots(1,1)\n",
    "ks = [1, 3, 5, 7, 9, 11, 15, 21, 35, 51]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "means = np.array(means).reshape(len(weights),len(ks))\n",
    "\n",
    "# Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "for idx, val in enumerate(weights):\n",
    "    ax.plot(ks, means[idx,:], '-o', label = \"Weights\" + ': ' + str(val))\n",
    "\n",
    "ax.set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "ax.set_xlabel(\"K\", fontsize=16)\n",
    "ax.set_ylabel('CV Average Score', fontsize=16)\n",
    "ax.legend(loc=\"best\", fontsize=15)\n",
    "ax.grid('on')\n",
    "# scores = [x[1] for x in knn_clf.grid_scores_]\n",
    "# scores = np.array(scores).reshape(len(tuned_parameters['weights']), len(tuned_parameters['n_neighbors']))\n",
    "\n",
    "# for ind, i in enumerate(tuned_parameters['weights']):\n",
    "#     plt.plot(tuned_parameters['n_neighbors'], scores[ind], label='Weight: ' + str(i))\n",
    "# plt.legend()\n",
    "# plt.xlabel('K')\n",
    "# plt.ylabel('Mean score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm cross validation \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['linear'], 'gamma': [0.1,0.05], 'C': [1e-1, 1, 10]}]\n",
    "\n",
    "print(\"# Tuning SVM hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "svm_clf = GridSearchCV(svm.SVC(), tuned_parameters, weighted_accuracy_score)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(svm_clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = svm_clf.cv_results_['mean_test_score']\n",
    "stds = svm_clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, svm_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, svm_clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.5)\n",
    "\n",
    "# regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "# regressor.fit(X_train, y_train)\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# rfc_cv_score = cross_val_score(regressor, X, Y, cv=10, scoring=weighted_accuracy_score)\n",
    "\n",
    "# print(\"=== Confusion Matrix ===\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print('\\n')\n",
    "# print(\"=== Classification Report ===\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print('\\n')\n",
    "# print(\"=== All AUC Scores ===\")\n",
    "# print(rfc_cv_score)\n",
    "# print('\\n')\n",
    "# print(\"=== Mean AUC Score ===\")\n",
    "# print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Random Forest hyper-parameters for weighted accuracy\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_estimators': 10}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.996 (+/-0.002) for {'n_estimators': 2}\n",
      "0.994 (+/-0.003) for {'n_estimators': 5}\n",
      "0.998 (+/-0.002) for {'n_estimators': 10}\n",
      "0.997 (+/-0.004) for {'n_estimators': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      2771\n",
      "           1       0.99      1.00      1.00      1402\n",
      "\n",
      "    accuracy                           1.00      4173\n",
      "   macro avg       1.00      1.00      1.00      4173\n",
      "weighted avg       1.00      1.00      1.00      4173\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#third try on decision tree\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [2, 5, 10, 20]}]\n",
    "\n",
    "print(\"# Tuning Random Forest hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "rf_clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring=weighted_accuracy_score)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(rf_clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = rf_clf.cv_results_['mean_test_score']\n",
    "stds = rf_clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, rf_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, rf_clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Logistic Regression hyper-parameters for weighted accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 10.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 10.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 100.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 100.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 1000.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.500 (+/-0.000) for {'C': 1000.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2727\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.98      2793\n",
      "   macro avg       0.49      0.50      0.49      2793\n",
      "weighted avg       0.95      0.98      0.96      2793\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#fourth try on logistic regression with l1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = {'C' : np.logspace(-3,3,7), 'penalty':['l1','l2'], 'solver':['saga']}\n",
    "\n",
    "print(\"# Tuning Logistic Regression hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "logreg_cv = GridSearchCV(LogisticRegression(),tuned_parameters, scoring = weighted_accuracy_score)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(logreg_cv.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = logreg_cv.cv_results_['mean_test_score']\n",
    "stds = logreg_cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, logreg_cv.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, logreg_cv.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on original data (no duplicates)\n",
    "Y = df['ipo']\n",
    "X = df[features]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.3, stratify = Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: insert best parameter here\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 9)\n",
    "knn_model.fit(X_train, Y_train)\n",
    "knn_pred = knn_model.predict(X_val)\n",
    "    \n",
    "print(\"The weighted accuracy for knn is:\", weighted_accuracy(knn_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: insert best parameter here\n",
    "svm_model = svm.SVC(C = 1, gamma = 0.1, kernel = 'linear')\n",
    "svm_model.fit(X_train, Y_train)\n",
    "svm_pred = svm_model.predict(X_val)\n",
    "\n",
    "print(\"The weighted accuracy for svm is:\", weighted_accuracy(svm_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted accuracy for random forest is: 0.5503575304858584\n"
     ]
    }
   ],
   "source": [
    "#TODO: insert best parameter here\n",
    "rf_model =RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rf_model.fit(X_train, Y_train)\n",
    "rf_pred = rf_model.predict(X_val)\n",
    "\n",
    "print(\"The weighted accuracy for random forest is:\", weighted_accuracy(rf_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted accuracy for logit is: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ORIE4740/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#TODO: insert best parameter here\n",
    "logit_model = LogisticRegression(penalty = 'l1', solver = 'saga',C = 0.001)\n",
    "logit_model.fit(X_train, Y_train)\n",
    "logit_pred = logit_model.predict(X_val)\n",
    "\n",
    "print(\"The weighted accuracy for logit is:\", weighted_accuracy(logit_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
