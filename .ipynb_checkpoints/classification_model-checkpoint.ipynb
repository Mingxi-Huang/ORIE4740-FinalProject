{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project : IPO prediction (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, confusion_matrix, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ipo</th>\n",
       "      <th>name</th>\n",
       "      <th>funded_object_id</th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wetpaint</td>\n",
       "      <td>c:1</td>\n",
       "      <td>9</td>\n",
       "      <td>39750000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FriendFeed</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobclix</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>c:10015</td>\n",
       "      <td>19</td>\n",
       "      <td>68069200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>MTPV</td>\n",
       "      <td>c:100155</td>\n",
       "      <td>5</td>\n",
       "      <td>10125293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ipo        name funded_object_id  num_investors  \\\n",
       "0           0    0    Wetpaint              c:1              9   \n",
       "1           1    0  FriendFeed           c:1001              3   \n",
       "2           2    0     Mobclix          c:10014              1   \n",
       "3           3    0      Fitbit          c:10015             19   \n",
       "4           4    0        MTPV         c:100155              5   \n",
       "\n",
       "   raised_amount_usd  type_Bachelor  type_Master  type_Other  \\\n",
       "0         39750000.0            7.0          5.0         1.0   \n",
       "1          5000000.0            4.0          6.0         0.0   \n",
       "2                0.0            2.0          1.0         2.0   \n",
       "3         68069200.0            2.0          7.0         2.0   \n",
       "4         10125293.0            1.0          3.0         0.0   \n",
       "\n",
       "   type_OtherDiploma  ...  state_TN  state_TX  state_UT  state_VA  state_VT  \\\n",
       "0                0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1                0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2                0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3                0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4                0.0  ...       0.0       1.0       0.0       0.0       0.0   \n",
       "\n",
       "   state_WA  state_WI  state_WV  state_WY  state_not specified  \n",
       "0       1.0       0.0       0.0       0.0                  0.0  \n",
       "1       0.0       0.0       0.0       0.0                  0.0  \n",
       "2       0.0       0.0       0.0       0.0                  0.0  \n",
       "3       0.0       0.0       0.0       0.0                  0.0  \n",
       "4       0.0       0.0       0.0       0.0                  0.0  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_final.csv\")\n",
    "df.head()\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipo</th>\n",
       "      <th>name</th>\n",
       "      <th>funded_object_id</th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wetpaint</td>\n",
       "      <td>c:1</td>\n",
       "      <td>9</td>\n",
       "      <td>39750000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>FriendFeed</td>\n",
       "      <td>c:1001</td>\n",
       "      <td>3</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mobclix</td>\n",
       "      <td>c:10014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>c:10015</td>\n",
       "      <td>19</td>\n",
       "      <td>68069200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MTPV</td>\n",
       "      <td>c:100155</td>\n",
       "      <td>5</td>\n",
       "      <td>10125293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9302</th>\n",
       "      <td>0</td>\n",
       "      <td>DECA</td>\n",
       "      <td>c:990</td>\n",
       "      <td>7</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>0</td>\n",
       "      <td>wunderloop</td>\n",
       "      <td>c:992</td>\n",
       "      <td>4</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9304</th>\n",
       "      <td>0</td>\n",
       "      <td>FastCustomer</td>\n",
       "      <td>c:99669</td>\n",
       "      <td>6</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305</th>\n",
       "      <td>0</td>\n",
       "      <td>Zimbra</td>\n",
       "      <td>c:997</td>\n",
       "      <td>9</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>0</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>c:9972</td>\n",
       "      <td>14</td>\n",
       "      <td>82500000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9307 rows Ã— 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ipo          name funded_object_id  num_investors  raised_amount_usd  \\\n",
       "0       0      Wetpaint              c:1              9         39750000.0   \n",
       "1       0    FriendFeed           c:1001              3          5000000.0   \n",
       "2       0       Mobclix          c:10014              1                0.0   \n",
       "3       0        Fitbit          c:10015             19         68069200.0   \n",
       "4       0          MTPV         c:100155              5         10125293.0   \n",
       "...   ...           ...              ...            ...                ...   \n",
       "9302    0          DECA            c:990              7         15000000.0   \n",
       "9303    0    wunderloop            c:992              4         10000000.0   \n",
       "9304    0  FastCustomer          c:99669              6           750000.0   \n",
       "9305    0        Zimbra            c:997              9         14500000.0   \n",
       "9306    0          Lyft           c:9972             14         82500000.0   \n",
       "\n",
       "      type_Bachelor  type_Master  type_Other  type_OtherDiploma  type_PhD  \\\n",
       "0               7.0          5.0         1.0                0.0       1.0   \n",
       "1               4.0          6.0         0.0                0.0       1.0   \n",
       "2               2.0          1.0         2.0                0.0       1.0   \n",
       "3               2.0          7.0         2.0                0.0       0.0   \n",
       "4               1.0          3.0         0.0                0.0       1.0   \n",
       "...             ...          ...         ...                ...       ...   \n",
       "9302            2.0          3.0         1.0                0.0       0.0   \n",
       "9303            1.0          4.0         2.0                0.0       0.0   \n",
       "9304            1.0          0.0         0.0                0.0       0.0   \n",
       "9305            2.0          7.0         2.0                0.0       1.0   \n",
       "9306            5.0          2.0         2.0                0.0       1.0   \n",
       "\n",
       "      ...  state_TN  state_TX  state_UT  state_VA  state_VT  state_WA  \\\n",
       "0     ...       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "1     ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2     ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3     ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4     ...       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "9302  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9303  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9304  ...       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "9305  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9306  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_WI  state_WV  state_WY  state_not specified  \n",
       "0          0.0       0.0       0.0                  0.0  \n",
       "1          0.0       0.0       0.0                  0.0  \n",
       "2          0.0       0.0       0.0                  0.0  \n",
       "3          0.0       0.0       0.0                  0.0  \n",
       "4          0.0       0.0       0.0                  0.0  \n",
       "...        ...       ...       ...                  ...  \n",
       "9302       0.0       0.0       0.0                  0.0  \n",
       "9303       0.0       0.0       0.0                  1.0  \n",
       "9304       0.0       0.0       0.0                  0.0  \n",
       "9305       0.0       0.0       0.0                  0.0  \n",
       "9306       0.0       0.0       0.0                  0.0  \n",
       "\n",
       "[9307 rows x 162 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_dup = df.append(df[df['ipo'] == 1] * 20, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_w_dup['ipo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_w_dup.columns\n",
    "features = features.drop(['name', 'ipo','funded_object_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_investors</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>type_Bachelor</th>\n",
       "      <th>type_Master</th>\n",
       "      <th>type_Other</th>\n",
       "      <th>type_OtherDiploma</th>\n",
       "      <th>type_PhD</th>\n",
       "      <th>subject_Accounting</th>\n",
       "      <th>subject_Accounting and Finance</th>\n",
       "      <th>subject_Advertising</th>\n",
       "      <th>...</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>state_not specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.041682</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>-0.027913</td>\n",
       "      <td>-0.020992</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>0.920750</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.180838</td>\n",
       "      <td>-0.062679</td>\n",
       "      <td>-0.024166</td>\n",
       "      <td>-0.019331</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.241083</td>\n",
       "      <td>-0.065700</td>\n",
       "      <td>-0.044031</td>\n",
       "      <td>-0.062242</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.301119</td>\n",
       "      <td>-0.024570</td>\n",
       "      <td>-0.044031</td>\n",
       "      <td>-0.010749</td>\n",
       "      <td>0.018944</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.082749</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.120594</td>\n",
       "      <td>-0.059582</td>\n",
       "      <td>-0.053964</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>0.924379</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9532</th>\n",
       "      <td>0.933689</td>\n",
       "      <td>0.085359</td>\n",
       "      <td>0.333410</td>\n",
       "      <td>0.100819</td>\n",
       "      <td>1.536531</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.082749</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9533</th>\n",
       "      <td>0.331242</td>\n",
       "      <td>0.175994</td>\n",
       "      <td>-0.063896</td>\n",
       "      <td>0.272462</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>2.162214</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9534</th>\n",
       "      <td>9.367949</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>1.723981</td>\n",
       "      <td>2.503821</td>\n",
       "      <td>0.737801</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>1.413893</td>\n",
       "      <td>7.317825</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>2.138583</td>\n",
       "      <td>1.102021</td>\n",
       "      <td>2.319941</td>\n",
       "      <td>0.787391</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>2.910535</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>19.867216</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9536</th>\n",
       "      <td>6.958161</td>\n",
       "      <td>3.905335</td>\n",
       "      <td>2.915900</td>\n",
       "      <td>2.160535</td>\n",
       "      <td>1.536531</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>0.665572</td>\n",
       "      <td>14.738751</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.036035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029621</td>\n",
       "      <td>-0.075032</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.02603</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.044961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9537 rows Ã— 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_investors  raised_amount_usd  type_Bachelor  type_Master  \\\n",
       "0         -0.000104          -0.041682       0.005632    -0.027913   \n",
       "1         -0.180838          -0.062679      -0.024166    -0.019331   \n",
       "2         -0.241083          -0.065700      -0.044031    -0.062242   \n",
       "3          0.301119          -0.024570      -0.044031    -0.010749   \n",
       "4         -0.120594          -0.059582      -0.053964    -0.045078   \n",
       "...             ...                ...            ...          ...   \n",
       "9532       0.933689           0.085359       0.333410     0.100819   \n",
       "9533       0.331242           0.175994      -0.063896     0.272462   \n",
       "9534       9.367949           0.466027       1.723981     2.503821   \n",
       "9535       2.138583           1.102021       2.319941     0.787391   \n",
       "9536       6.958161           3.905335       2.915900     2.160535   \n",
       "\n",
       "      type_Other  type_OtherDiploma  type_PhD  subject_Accounting  \\\n",
       "0      -0.020992          -0.029696 -0.045333           -0.103101   \n",
       "1      -0.060929          -0.029696 -0.045333           -0.103101   \n",
       "2       0.018944          -0.029696 -0.045333           -0.103101   \n",
       "3       0.018944          -0.029696 -0.082749           -0.103101   \n",
       "4      -0.060929          -0.029696 -0.045333           -0.103101   \n",
       "...          ...                ...       ...                 ...   \n",
       "9532    1.536531          -0.029696 -0.082749           -0.103101   \n",
       "9533   -0.060929          -0.029696  2.162214           -0.103101   \n",
       "9534    0.737801          -0.029696  1.413893            7.317825   \n",
       "9535   -0.060929          -0.029696  2.910535           -0.103101   \n",
       "9536    1.536531          -0.029696  0.665572           14.738751   \n",
       "\n",
       "      subject_Accounting and Finance  subject_Advertising  ...  state_TN  \\\n",
       "0                          -0.045438            -0.036035  ... -0.029621   \n",
       "1                          -0.045438            -0.036035  ... -0.029621   \n",
       "2                          -0.045438            -0.036035  ... -0.029621   \n",
       "3                          -0.045438            -0.036035  ... -0.029621   \n",
       "4                          -0.045438            -0.036035  ... -0.029621   \n",
       "...                              ...                  ...  ...       ...   \n",
       "9532                       -0.045438            -0.036035  ... -0.029621   \n",
       "9533                       -0.045438            -0.036035  ... -0.029621   \n",
       "9534                       -0.045438            -0.036035  ... -0.029621   \n",
       "9535                       -0.045438            -0.036035  ... -0.029621   \n",
       "9536                       -0.045438            -0.036035  ... -0.029621   \n",
       "\n",
       "      state_TX  state_UT  state_VA  state_VT   state_WA  state_WI  state_WV  \\\n",
       "0    -0.075032 -0.042832   -0.0594 -0.035494   0.920750  -0.02603 -0.014483   \n",
       "1    -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "2    -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "3    -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "4     0.924379 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "...        ...       ...       ...       ...        ...       ...       ...   \n",
       "9532 -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "9533 -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "9534 -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "9535 -0.075032 -0.042832   -0.0594 -0.035494  19.867216  -0.02603 -0.014483   \n",
       "9536 -0.075032 -0.042832   -0.0594 -0.035494  -0.076433  -0.02603 -0.014483   \n",
       "\n",
       "      state_WY  state_not specified  \n",
       "0    -0.014483            -0.044961  \n",
       "1    -0.014483            -0.044961  \n",
       "2    -0.014483            -0.044961  \n",
       "3    -0.014483            -0.044961  \n",
       "4    -0.014483            -0.044961  \n",
       "...        ...                  ...  \n",
       "9532 -0.014483            -0.044961  \n",
       "9533 -0.014483            -0.044961  \n",
       "9534 -0.014483            -0.044961  \n",
       "9535 -0.014483            -0.044961  \n",
       "9536 -0.014483            -0.044961  \n",
       "\n",
       "[9537 rows x 159 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling on features\n",
    "df_w_dup[features] = StandardScaler().fit_transform(df_w_dup[features])\n",
    "df_w_dup[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing weighted accuracy from CS4780\n",
    "def weighted_accuracy(pred, true):\n",
    "    assert(len(pred) == len(true))\n",
    "    num_labels = len(true)\n",
    "    num_pos = sum(true)\n",
    "    num_neg = num_labels - num_pos\n",
    "    frac_pos = num_pos/num_labels\n",
    "    weight_pos = 1/frac_pos\n",
    "    weight_neg = 1/(1-frac_pos)\n",
    "    num_pos_correct = 0\n",
    "    num_neg_correct = 0\n",
    "    for pred_i, true_i in zip(pred, true):\n",
    "        num_pos_correct += (pred_i == true_i and true_i == 1)\n",
    "        num_neg_correct += (pred_i == true_i and true_i == 0)\n",
    "    weighted_accuracy = ((weight_pos * num_pos_correct) \n",
    "                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))\n",
    "    return weighted_accuracy\n",
    "\n",
    "#custom scorer based on weighted accuracy function given\n",
    "def weighted_accuracy_switched(y, y_pred):\n",
    "    return weighted_accuracy(y_pred, y)\n",
    "\n",
    "weighted_accuracy_score = make_scorer(weighted_accuracy_switched, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_w_dup['ipo']\n",
    "X = df_w_dup[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.00)\n",
      "# Tuning KNN hyper-parameters for weighted accuracy\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.984 (+/-0.025) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.984 (+/-0.025) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.993 (+/-0.025) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.992 (+/-0.024) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.993 (+/-0.025) for {'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.993 (+/-0.026) for {'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.993 (+/-0.025) for {'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "0.993 (+/-0.025) for {'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.993 (+/-0.025) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.993 (+/-0.025) for {'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 35, 'weights': 'uniform'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 35, 'weights': 'distance'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 51, 'weights': 'uniform'}\n",
      "0.994 (+/-0.025) for {'n_neighbors': 51, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2729\n",
      "           1       0.75      0.04      0.08        69\n",
      "          20       1.00      0.48      0.65        64\n",
      "\n",
      "    accuracy                           0.97      2862\n",
      "   macro avg       0.91      0.51      0.57      2862\n",
      "weighted avg       0.96      0.97      0.95      2862\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first try on knn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = [{'n_neighbors':[1, 3, 5, 7, 9, 11, 15, 21, 35, 51], 'weights': ['uniform', 'distance']}]\n",
    "\n",
    "knn_cv = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_cv_scores = cross_val_score(knn_cv, X, Y, cv=5, scoring=weighted_accuracy_score)\n",
    "# knn_cv_scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (knn_cv_scores.mean(), knn_cv_scores.std() * 2))\n",
    "\n",
    "print(\"# Tuning KNN hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "knn_clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, scoring=weighted_accuracy_score)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(knn_clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = knn_clf.cv_results_['mean_test_score']\n",
    "stds = knn_clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, knn_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, knn_clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning SVM hyper-parameters for weighted accuracy\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.05, 'kernel': 'poly'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.05, 'kernel': 'linear'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.05, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.917 (+/-0.025) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.916 (+/-0.026) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.05, 'kernel': 'poly'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 0.1, 'gamma': 0.05, 'kernel': 'linear'}\n",
      "0.916 (+/-0.025) for {'C': 0.1, 'gamma': 0.05, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.917 (+/-0.025) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.914 (+/-0.023) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.910 (+/-0.025) for {'C': 1, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 1, 'gamma': 0.05, 'kernel': 'poly'}\n",
      "0.915 (+/-0.024) for {'C': 1, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 1, 'gamma': 0.05, 'kernel': 'linear'}\n",
      "0.914 (+/-0.025) for {'C': 1, 'gamma': 0.05, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.916 (+/-0.024) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.916 (+/-0.026) for {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.916 (+/-0.023) for {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.912 (+/-0.021) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.904 (+/-0.020) for {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.918 (+/-0.025) for {'C': 10, 'gamma': 0.05, 'kernel': 'poly'}\n",
      "0.914 (+/-0.023) for {'C': 10, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 10, 'gamma': 0.05, 'kernel': 'linear'}\n",
      "0.910 (+/-0.025) for {'C': 10, 'gamma': 0.05, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.916 (+/-0.025) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.916 (+/-0.026) for {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "0.913 (+/-0.025) for {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.910 (+/-0.022) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.895 (+/-0.027) for {'C': 100, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "0.915 (+/-0.023) for {'C': 100, 'gamma': 0.05, 'kernel': 'poly'}\n",
      "0.912 (+/-0.023) for {'C': 100, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 100, 'gamma': 0.05, 'kernel': 'linear'}\n",
      "0.899 (+/-0.025) for {'C': 100, 'gamma': 0.05, 'kernel': 'sigmoid'}\n",
      "0.917 (+/-0.025) for {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.916 (+/-0.024) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.918 (+/-0.025) for {'C': 100, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.912 (+/-0.024) for {'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2724\n",
      "           1       0.25      0.05      0.08        60\n",
      "          20       1.00      0.83      0.91        78\n",
      "\n",
      "    accuracy                           0.98      2862\n",
      "   macro avg       0.74      0.63      0.66      2862\n",
      "weighted avg       0.96      0.98      0.97      2862\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svm cross validation {'C': 10000.0, 'gamma': 0.05, 'kernel': 'rbf'}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['poly', 'rbf', 'linear', 'sigmoid'], 'gamma': [0.1,0.05,0.01], 'C': [1e-2, 1e-1, 1, 10, 100]}]\n",
    "\n",
    "print(\"# Tuning SVM hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "svm_clf = GridSearchCV(svm.SVC(), tuned_parameters, weighted_accuracy_score)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(svm_clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = svm_clf.cv_results_['mean_test_score']\n",
    "stds = svm_clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, svm_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, svm_clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.5)\n",
    "\n",
    "# regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "# regressor.fit(X_train, y_train)\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# rfc_cv_score = cross_val_score(regressor, X, Y, cv=10, scoring=weighted_accuracy_score)\n",
    "\n",
    "# print(\"=== Confusion Matrix ===\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print('\\n')\n",
    "# print(\"=== Classification Report ===\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print('\\n')\n",
    "# print(\"=== All AUC Scores ===\")\n",
    "# print(rfc_cv_score)\n",
    "# print('\\n')\n",
    "# print(\"=== Mean AUC Score ===\")\n",
    "# print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Random Forest hyper-parameters for weighted accuracy\n",
      "\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_estimators': 10}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.969 (+/-0.032) for {'n_estimators': 2}\n",
      "0.969 (+/-0.030) for {'n_estimators': 5}\n",
      "0.971 (+/-0.028) for {'n_estimators': 10}\n",
      "0.971 (+/-0.028) for {'n_estimators': 20}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2728\n",
      "           1       0.75      0.09      0.16        66\n",
      "          20       1.00      0.97      0.99        68\n",
      "\n",
      "    accuracy                           0.98      2862\n",
      "   macro avg       0.91      0.69      0.71      2862\n",
      "weighted avg       0.97      0.98      0.97      2862\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#third try on decision tree\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [2, 5, 10, 20]}]\n",
    "\n",
    "print(\"# Tuning Random Forest hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "rf_clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring=weighted_accuracy_score)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(rf_clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = rf_clf.cv_results_['mean_test_score']\n",
    "stds = rf_clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, rf_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, rf_clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Logistic Regression hyper-parameters for weighted accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.953 (+/-0.022) for {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.953 (+/-0.022) for {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.953 (+/-0.022) for {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.953 (+/-0.021) for {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.953 (+/-0.021) for {'C': 10.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.953 (+/-0.021) for {'C': 100.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.953 (+/-0.021) for {'C': 1000.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2720\n",
      "           1       0.00      0.00      0.00        71\n",
      "          20       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.95      2862\n",
      "   macro avg       0.32      0.33      0.32      2862\n",
      "weighted avg       0.90      0.95      0.93      2862\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/dongqing_wang/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#fourth try on logistic regression with l1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "\n",
    "tuned_parameters = {'C' : np.logspace(-3,3,7), 'penalty':['l1'], 'solver':['saga']}\n",
    "\n",
    "print(\"# Tuning Logistic Regression hyper-parameters for weighted accuracy\")\n",
    "print()\n",
    "\n",
    "logreg_cv = GridSearchCV(LogisticRegression(),tuned_parameters, scoring = weighted_accuracy_score)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters set found on train set:\")\n",
    "print()\n",
    "print(logreg_cv.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on train set:\")\n",
    "print()\n",
    "means = logreg_cv.cv_results_['mean_test_score']\n",
    "stds = logreg_cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, logreg_cv.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full train set.\")\n",
    "print(\"The scores are computed on the full test set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, logreg_cv.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on original data (no duplicates)\n",
    "# Y = df['ipo']\n",
    "# X = df[features]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted accuracy for knn is: 0.9381130228523197\n"
     ]
    }
   ],
   "source": [
    "#TODO: insert best parameter here\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 9)\n",
    "knn_model.fit(X_train, Y_train)\n",
    "knn_pred = knn_model.predict(X_val)\n",
    "    \n",
    "print(\"The weighted accuracy for knn is:\", weighted_accuracy(knn_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted accuracy for svm is: 0.9377691438977115\n"
     ]
    }
   ],
   "source": [
    "#TODO: insert best parameter here\n",
    "svm_model = svm.SVC(C = 100, gamma = 0.1, kernel = 'linear')\n",
    "svm_model.fit(X_train, Y_train)\n",
    "svm_pred = svm_model.predict(X_val)\n",
    "\n",
    "print(\"The weighted accuracy for svm is:\", weighted_accuracy(svm_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted accuracy for random forest is: 0.9381467268975867\n"
     ]
    }
   ],
   "source": [
    "#TODO: insert best parameter here\n",
    "rf_model =RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rf_model.fit(X_train, Y_train)\n",
    "rf_pred = rf_model.predict(X_val)\n",
    "\n",
    "print(\"The weighted accuracy for random forest is:\", weighted_accuracy(rf_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted accuracy for logit is: 0.937757909215956\n"
     ]
    }
   ],
   "source": [
    "#TODO: insert best parameter here\n",
    "logit_model = LogisticRegression(penalty = 'l1', solver = 'saga',C = 0.001)\n",
    "logit_model.fit(X_train, Y_train)\n",
    "logit_pred = logit_model.predict(X_val)\n",
    "\n",
    "print(\"The weighted accuracy for logit is:\", weighted_accuracy(logit_pred, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
